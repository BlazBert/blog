{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d5247ee1",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Quarto Basics\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d56871f-eeb8-47c4-9b30-543c4ea4265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.19.5)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (2.6.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (1.7.2)\n",
      "Requirement already satisfied: tables in /opt/conda/lib/python3.9/site-packages (3.6.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: hmmlearn in /opt/conda/lib/python3.9/site-packages (0.2.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (6.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.9/site-packages (1.6.2)\n",
      "Requirement already satisfied: pyts in /opt/conda/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.9/site-packages (from tables) (2.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numba>=0.48.0 in /opt/conda/lib/python3.9/site-packages (from pyts) (0.54.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (59.1.1)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (0.37.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Collecting git+https://github.com/nilmtk/nilmtk@master\n",
      "  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-n33khpe3\n",
      "  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilmtk /tmp/pip-req-build-n33khpe3\n",
      "  Resolved https://github.com/nilmtk/nilmtk to commit dde510b7b2299958597a6b3885230844c1b7e9da\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilmtk\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.dde510b-py3-none-any.whl size=279071 sha256=563beb09bc9828fc29456f6f913b50165f54a959d586726199abf4165057283d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sk3qzvei/wheels/05/f2/54/7dc6179b2887926915ea9f94c7d02d7c097f9e22a6fdaad502\n",
      "Successfully built nilmtk\n",
      "Installing collected packages: nilmtk\n",
      "Successfully installed nilmtk-0.4.0.dev1+git.dde510b\n",
      "Collecting git+https://github.com/nilmtk/nilm_metadata@master\n",
      "  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-r1tg6i8d\n",
      "  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-r1tg6i8d\n",
      "  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24356 sha256=1caad9d0b49a25c3553b343895e4f987a9d939b950da723a5138cfe57a77bbb4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ra9ynsow/wheels/47/14/89/78d651fffdf1c6ba8d7247addd79b87e5236c914c648d03310\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.5\n"
     ]
    }
   ],
   "source": [
    "#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n",
    "!pip uninstall -y -q nilmtk nilm_metadata\n",
    "!python3 -m pip install pandas numpy networkx scipy tables scikit-learn hmmlearn pyyaml matplotlib xgboost pyts\n",
    "# Trick to install NILM regardless of its dependencies\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n",
    "!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa65755-93dd-4478-8e18-e86678172b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd44d67-1bd1-413f-babf-486af9a3b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import nilmtk\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168de01f-722b-44a8-bcb1-7901fbf6cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select initial parameters\n",
    "\n",
    "#name of nilmtk dataset file\n",
    "originname=\"SynD.h5\"\n",
    "\n",
    "#path of folder with the dataset\n",
    "originpath=\"\"\n",
    "\n",
    "#where to output processed data\n",
    "destinationpath=\"\"\n",
    "\n",
    "#desired sample length in minutes, assumes sample rate of 1/6s\n",
    "n_mins=15\n",
    "\n",
    "#samples are created with a sliding window. this is the step as a proportion of resolution\n",
    "step_ratio=0.5\n",
    "\n",
    "#how to deal with nan values (delete/replace with 0/lerp)\n",
    "method=\"zero fill\" #\"stitch\", \"zero fill\" or \"interpolate\"\n",
    "\n",
    "#removes samples with an average power in watts lower than this\n",
    "min_watts=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e976bffc-f04a-43b8-9875-1a04cede2a70",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file as SynD.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43/3991786710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnilmtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moriginname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#iterates through all meters and gets unique devices in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nilmtk/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, format)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_datastore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimport_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nilmtk/utils.py\u001b[0m in \u001b[0;36mget_datastore\u001b[0;34m(filename, format, mode)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HDF\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mHDFDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CSV\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCSVDataStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nilmtk/docinherit.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nilmtk/datastore/hdfdatastore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file as \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: No such file as SynD.h5"
     ]
    }
   ],
   "source": [
    "#for measuring execution time\n",
    "from time import process_time\n",
    "t = process_time()\n",
    "\n",
    "#step calculation based on resolution and step ratio, this is the \n",
    "step_mins=n_mins*step_ratio\n",
    "step=int(step_mins*10)\n",
    "\n",
    "#name of input file, will be used to name output files\n",
    "name=os.path.splitext(originname)[0]\n",
    "\n",
    "#load dataset\n",
    "dataset=nilmtk.DataSet(originpath+originname)\n",
    "\n",
    "#iterates through all meters and gets unique devices in the dataset\n",
    "devices=[]\n",
    "for building in dataset.buildings:\n",
    "  for meter in dataset.buildings[building].elec.submeters().meters:\n",
    "    label=meter.appliances[0].metadata.get(\"type\") #string with name of device for example \"fridge\"\n",
    "    devices.append(str(label))\n",
    "devices=np.sort(np.unique(np.array(devices))) #removes duplicates and sorts alphabetically\n",
    "\n",
    "#dictionary of unique devices in the dataset\n",
    "devicedict={}\n",
    "for i, device in enumerate(devices):\n",
    "  devicedict[device]=i\n",
    "\n",
    "#save dictionary to a pickle file\n",
    "with open(\"\"+name+\"_devicedict.pkl\", \"wb\") as f:\n",
    "  pickle.dump(devices, f)\n",
    "\n",
    "#arrays where processed data will be temporarily stored. \n",
    "#data and labels store samples and labels \n",
    "#the other three store information about total data points, not nan data points and retained data points after sample creation respectively\n",
    "data=[]\n",
    "labels=[]\n",
    "stattotal=[]\n",
    "statnotnan=[]\n",
    "statretained=[]\n",
    "\n",
    "#60s/sample time in seconds=10, this is the number of data points in a sample\n",
    "sample_length=n_mins*10\n",
    "\n",
    "#iterate through all meters\n",
    "for building in dataset.buildings:\n",
    "  for meter in dataset.buildings[building].elec.submeters().meters:\n",
    "    label=meter.appliances[0].metadata.get(\"type\")\n",
    "    #use electrical power data and store in a pandas dataframe\n",
    "    df = next(meter.load(physical_quantity='power'))\n",
    "    #resamples to 6s, as thats the most commonly shared sample rate\n",
    "    df=df.resample(\"6s\").ffill(limit=10)\n",
    "    #gets time series of power values, uses active power if possible, else apparent power\n",
    "    try:\n",
    "        ts = np.array(df.power.active.values)\n",
    "    except:\n",
    "        try:\n",
    "            ts = np.array(df.power.apparent.values)\n",
    "        except:\n",
    "            raise ValueError\n",
    "\n",
    "    #collects info about the length of raw ts      \n",
    "    print(f\"starting: {label}\")\n",
    "    length=len(ts)\n",
    "    print(f\"raw series length: {length}\")\n",
    "    stattotal.append(length)\n",
    "    \n",
    "    #transforms the raw time series based on the selected type\n",
    "    if method==\"stitch\":\n",
    "        #deletes nan data points\n",
    "      ts=ts[~np.isnan(ts)]\n",
    "    elif method==\"zero fill\":\n",
    "        #replaces nan data points with 0\n",
    "      ts[np.isnan(ts)]=0\n",
    "    elif method==\"interpolate\":\n",
    "        #interpolates nan data points (linear by default)\n",
    "      ts=np.array(pd.Series(ts).interpolate())\n",
    "    \n",
    "    #collects info about the number of not nan data points\n",
    "    length=len(ts)\n",
    "    print(f\"cleaned series length: {length}\")\n",
    "    statnotnan.append(length)\n",
    "    \n",
    "    #sample creation from time series, sliding window with calculated step\n",
    "    n_samples=length//(sample_length-step)\n",
    "    \n",
    "    #split time series into segments based on the selected length and step\n",
    "    count=0\n",
    "    for i in range(n_samples):\n",
    "      sample=ts[i*step:i*step+sample_length]\n",
    "      #only use samples where average power is above the threshold else discard them\n",
    "      if np.mean(sample)>=min_watts:\n",
    "        data.append(sample)\n",
    "        labels.append(label)\n",
    "        count+=1\n",
    "    \n",
    "    #info about retained data\n",
    "    statretained.append(count*sample_length)\n",
    "    print(f\"finished: {label}, created {count} samples\\n\")\n",
    "\n",
    "#output collected info (how many data points)\n",
    "print(f\"retained {np.sum(statnotnan)} out of {np.sum(stattotal)} data points\")\n",
    "print(f\"retained {np.sum(statretained)} data points after sample creation ({np.sum(statretained)//sample_length} samples)\\n\")\n",
    "\n",
    "#save data in shape (number of samples, minutes*10) and labels in shape (number of samples)\n",
    "data=np.array(data)\n",
    "labels=np.array(labels)\n",
    "np.save(destinationpath+name+\"_data_\"+str(n_mins)+\".npy\", data, allow_pickle=False)\n",
    "np.save(destinationpath+name+\"_labels_\"+str(n_mins)+\".npy\", labels, allow_pickle=False)\n",
    "\n",
    "#print execution time\n",
    "elapsed_time=process_time()-t\n",
    "print(f\"done in {elapsed_time} seconds\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e76eaa14598b43c5851c3426c404d429761cef3331a5cc17f59e17309014117c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
