[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog_BB",
    "section": "",
    "text": "Quarto Basics\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/sample creation (3).html",
    "href": "posts/sample creation (3).html",
    "title": "Quarto Basics",
    "section": "",
    "text": "Code\n#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n!pip uninstall -y -q nilmtk nilm_metadata\n!python3 -m pip install pandas numpy networkx scipy tables scikit-learn hmmlearn pyyaml matplotlib xgboost pyts\n# Trick to install NILM regardless of its dependencies\n!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master\n\n\nRequirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.19.5)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (2.6.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (1.7.2)\nRequirement already satisfied: tables in /opt/conda/lib/python3.9/site-packages (3.6.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.0.1)\nRequirement already satisfied: hmmlearn in /opt/conda/lib/python3.9/site-packages (0.2.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (6.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.4.3)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.9/site-packages (1.6.2)\nRequirement already satisfied: pyts in /opt/conda/lib/python3.9/site-packages (0.12.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\nRequirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.9/site-packages (from tables) (2.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.0.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (8.4.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: numba>=0.48.0 in /opt/conda/lib/python3.9/site-packages (from pyts) (0.54.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (59.1.1)\nRequirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (0.37.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nCollecting git+https://github.com/nilmtk/nilmtk@master\n  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-n33khpe3\n  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilmtk /tmp/pip-req-build-n33khpe3\n  Resolved https://github.com/nilmtk/nilmtk to commit dde510b7b2299958597a6b3885230844c1b7e9da\n  Preparing metadata (setup.py) ... done\nBuilding wheels for collected packages: nilmtk\n  Building wheel for nilmtk (setup.py) ... done\n  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.dde510b-py3-none-any.whl size=279071 sha256=563beb09bc9828fc29456f6f913b50165f54a959d586726199abf4165057283d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-sk3qzvei/wheels/05/f2/54/7dc6179b2887926915ea9f94c7d02d7c097f9e22a6fdaad502\nSuccessfully built nilmtk\nInstalling collected packages: nilmtk\nSuccessfully installed nilmtk-0.4.0.dev1+git.dde510b\nCollecting git+https://github.com/nilmtk/nilm_metadata@master\n  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-r1tg6i8d\n  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-r1tg6i8d\n  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n  Preparing metadata (setup.py) ... done\nBuilding wheels for collected packages: nilm-metadata\n  Building wheel for nilm-metadata (setup.py) ... done\n  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24356 sha256=1caad9d0b49a25c3553b343895e4f987a9d939b950da723a5138cfe57a77bbb4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ra9ynsow/wheels/47/14/89/78d651fffdf1c6ba8d7247addd79b87e5236c914c648d03310\nSuccessfully built nilm-metadata\nInstalling collected packages: nilm-metadata\nSuccessfully installed nilm-metadata-0.2.5\n\n\n\n\nCode\nimport h5py\nimport numpy as np\nimport nilmtk\nimport os\nimport pickle\nimport pandas as pd\n\n\n\n\nCode\n#select initial parameters\n\n#name of nilmtk dataset file\noriginname=\"SynD.h5\"\n\n#path of folder with the dataset\noriginpath=\"\"\n\n#where to output processed data\ndestinationpath=\"\"\n\n#desired sample length in minutes, assumes sample rate of 1/6s\nn_mins=15\n\n#samples are created with a sliding window. this is the step as a proportion of resolution\nstep_ratio=0.5\n\n#how to deal with nan values (delete/replace with 0/lerp)\nmethod=\"zero fill\" #\"stitch\", \"zero fill\" or \"interpolate\"\n\n#removes samples with an average power in watts lower than this\nmin_watts=1\n\n\n\n\nCode\n#for measuring execution time\nfrom time import process_time\nt = process_time()\n\n#step calculation based on resolution and step ratio, this is the \nstep_mins=n_mins*step_ratio\nstep=int(step_mins*10)\n\n#name of input file, will be used to name output files\nname=os.path.splitext(originname)[0]\n\n#load dataset\ndataset=nilmtk.DataSet(originpath+originname)\n\n#iterates through all meters and gets unique devices in the dataset\ndevices=[]\nfor building in dataset.buildings:\n  for meter in dataset.buildings[building].elec.submeters().meters:\n    label=meter.appliances[0].metadata.get(\"type\") #string with name of device for example \"fridge\"\n    devices.append(str(label))\ndevices=np.sort(np.unique(np.array(devices))) #removes duplicates and sorts alphabetically\n\n#dictionary of unique devices in the dataset\ndevicedict={}\nfor i, device in enumerate(devices):\n  devicedict[device]=i\n\n#save dictionary to a pickle file\nwith open(\"\"+name+\"_devicedict.pkl\", \"wb\") as f:\n  pickle.dump(devices, f)\n\n#arrays where processed data will be temporarily stored. \n#data and labels store samples and labels \n#the other three store information about total data points, not nan data points and retained data points after sample creation respectively\ndata=[]\nlabels=[]\nstattotal=[]\nstatnotnan=[]\nstatretained=[]\n\n#60s/sample time in seconds=10, this is the number of data points in a sample\nsample_length=n_mins*10\n\n#iterate through all meters\nfor building in dataset.buildings:\n  for meter in dataset.buildings[building].elec.submeters().meters:\n    label=meter.appliances[0].metadata.get(\"type\")\n    #use electrical power data and store in a pandas dataframe\n    df = next(meter.load(physical_quantity='power'))\n    #resamples to 6s, as thats the most commonly shared sample rate\n    df=df.resample(\"6s\").ffill(limit=10)\n    #gets time series of power values, uses active power if possible, else apparent power\n    try:\n        ts = np.array(df.power.active.values)\n    except:\n        try:\n            ts = np.array(df.power.apparent.values)\n        except:\n            raise ValueError\n\n    #collects info about the length of raw ts      \n    print(f\"starting: {label}\")\n    length=len(ts)\n    print(f\"raw series length: {length}\")\n    stattotal.append(length)\n    \n    #transforms the raw time series based on the selected type\n    if method==\"stitch\":\n        #deletes nan data points\n      ts=ts[~np.isnan(ts)]\n    elif method==\"zero fill\":\n        #replaces nan data points with 0\n      ts[np.isnan(ts)]=0\n    elif method==\"interpolate\":\n        #interpolates nan data points (linear by default)\n      ts=np.array(pd.Series(ts).interpolate())\n    \n    #collects info about the number of not nan data points\n    length=len(ts)\n    print(f\"cleaned series length: {length}\")\n    statnotnan.append(length)\n    \n    #sample creation from time series, sliding window with calculated step\n    n_samples=length//(sample_length-step)\n    \n    #split time series into segments based on the selected length and step\n    count=0\n    for i in range(n_samples):\n      sample=ts[i*step:i*step+sample_length]\n      #only use samples where average power is above the threshold else discard them\n      if np.mean(sample)>=min_watts:\n        data.append(sample)\n        labels.append(label)\n        count+=1\n    \n    #info about retained data\n    statretained.append(count*sample_length)\n    print(f\"finished: {label}, created {count} samples\\n\")\n\n#output collected info (how many data points)\nprint(f\"retained {np.sum(statnotnan)} out of {np.sum(stattotal)} data points\")\nprint(f\"retained {np.sum(statretained)} data points after sample creation ({np.sum(statretained)//sample_length} samples)\\n\")\n\n#save data in shape (number of samples, minutes*10) and labels in shape (number of samples)\ndata=np.array(data)\nlabels=np.array(labels)\nnp.save(destinationpath+name+\"_data_\"+str(n_mins)+\".npy\", data, allow_pickle=False)\nnp.save(destinationpath+name+\"_labels_\"+str(n_mins)+\".npy\", labels, allow_pickle=False)\n\n#print execution time\nelapsed_time=process_time()-t\nprint(f\"done in {elapsed_time} seconds\\n\")\n\n\nOSError: No such file as SynD.h5"
  },
  {
    "objectID": "posts/notebook_post/sample creation (3).html",
    "href": "posts/notebook_post/sample creation (3).html",
    "title": "Quarto Basics",
    "section": "",
    "text": "Code\n#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n!pip uninstall -y -q nilmtk nilm_metadata\n!python3 -m pip install pandas numpy networkx scipy tables scikit-learn hmmlearn pyyaml matplotlib xgboost pyts\n# Trick to install NILM regardless of its dependencies\n!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master\n\n\nRequirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.19.5)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (2.6.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (1.7.2)\nRequirement already satisfied: tables in /opt/conda/lib/python3.9/site-packages (3.6.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.0.1)\nRequirement already satisfied: hmmlearn in /opt/conda/lib/python3.9/site-packages (0.2.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (6.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.4.3)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.9/site-packages (1.6.2)\nRequirement already satisfied: pyts in /opt/conda/lib/python3.9/site-packages (0.12.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\nRequirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.9/site-packages (from tables) (2.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.0.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (8.4.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: numba>=0.48.0 in /opt/conda/lib/python3.9/site-packages (from pyts) (0.54.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (59.1.1)\nRequirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (0.37.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nCollecting git+https://github.com/nilmtk/nilmtk@master\n  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-n33khpe3\n  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilmtk /tmp/pip-req-build-n33khpe3\n  Resolved https://github.com/nilmtk/nilmtk to commit dde510b7b2299958597a6b3885230844c1b7e9da\n  Preparing metadata (setup.py) ... done\nBuilding wheels for collected packages: nilmtk\n  Building wheel for nilmtk (setup.py) ... done\n  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.dde510b-py3-none-any.whl size=279071 sha256=563beb09bc9828fc29456f6f913b50165f54a959d586726199abf4165057283d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-sk3qzvei/wheels/05/f2/54/7dc6179b2887926915ea9f94c7d02d7c097f9e22a6fdaad502\nSuccessfully built nilmtk\nInstalling collected packages: nilmtk\nSuccessfully installed nilmtk-0.4.0.dev1+git.dde510b\nCollecting git+https://github.com/nilmtk/nilm_metadata@master\n  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-r1tg6i8d\n  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-r1tg6i8d\n  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n  Preparing metadata (setup.py) ... done\nBuilding wheels for collected packages: nilm-metadata\n  Building wheel for nilm-metadata (setup.py) ... done\n  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24356 sha256=1caad9d0b49a25c3553b343895e4f987a9d939b950da723a5138cfe57a77bbb4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ra9ynsow/wheels/47/14/89/78d651fffdf1c6ba8d7247addd79b87e5236c914c648d03310\nSuccessfully built nilm-metadata\nInstalling collected packages: nilm-metadata\nSuccessfully installed nilm-metadata-0.2.5\n\n\n\n\nCode\nimport h5py\nimport numpy as np\nimport nilmtk\nimport os\nimport pickle\nimport pandas as pd\n\n\n\n\nCode\n#select initial parameters\n\n#name of nilmtk dataset file\noriginname=\"SynD.h5\"\n\n#path of folder with the dataset\noriginpath=\"\"\n\n#where to output processed data\ndestinationpath=\"\"\n\n#desired sample length in minutes, assumes sample rate of 1/6s\nn_mins=15\n\n#samples are created with a sliding window. this is the step as a proportion of resolution\nstep_ratio=0.5\n\n#how to deal with nan values (delete/replace with 0/lerp)\nmethod=\"zero fill\" #\"stitch\", \"zero fill\" or \"interpolate\"\n\n#removes samples with an average power in watts lower than this\nmin_watts=1\n\n\n\n\nCode\n#for measuring execution time\nfrom time import process_time\nt = process_time()\n\n#step calculation based on resolution and step ratio, this is the \nstep_mins=n_mins*step_ratio\nstep=int(step_mins*10)\n\n#name of input file, will be used to name output files\nname=os.path.splitext(originname)[0]\n\n#load dataset\ndataset=nilmtk.DataSet(originpath+originname)\n\n#iterates through all meters and gets unique devices in the dataset\ndevices=[]\nfor building in dataset.buildings:\n  for meter in dataset.buildings[building].elec.submeters().meters:\n    label=meter.appliances[0].metadata.get(\"type\") #string with name of device for example \"fridge\"\n    devices.append(str(label))\ndevices=np.sort(np.unique(np.array(devices))) #removes duplicates and sorts alphabetically\n\n#dictionary of unique devices in the dataset\ndevicedict={}\nfor i, device in enumerate(devices):\n  devicedict[device]=i\n\n#save dictionary to a pickle file\nwith open(\"\"+name+\"_devicedict.pkl\", \"wb\") as f:\n  pickle.dump(devices, f)\n\n#arrays where processed data will be temporarily stored. \n#data and labels store samples and labels \n#the other three store information about total data points, not nan data points and retained data points after sample creation respectively\ndata=[]\nlabels=[]\nstattotal=[]\nstatnotnan=[]\nstatretained=[]\n\n#60s/sample time in seconds=10, this is the number of data points in a sample\nsample_length=n_mins*10\n\n#iterate through all meters\nfor building in dataset.buildings:\n  for meter in dataset.buildings[building].elec.submeters().meters:\n    label=meter.appliances[0].metadata.get(\"type\")\n    #use electrical power data and store in a pandas dataframe\n    df = next(meter.load(physical_quantity='power'))\n    #resamples to 6s, as thats the most commonly shared sample rate\n    df=df.resample(\"6s\").ffill(limit=10)\n    #gets time series of power values, uses active power if possible, else apparent power\n    try:\n        ts = np.array(df.power.active.values)\n    except:\n        try:\n            ts = np.array(df.power.apparent.values)\n        except:\n            raise ValueError\n\n    #collects info about the length of raw ts      \n    print(f\"starting: {label}\")\n    length=len(ts)\n    print(f\"raw series length: {length}\")\n    stattotal.append(length)\n    \n    #transforms the raw time series based on the selected type\n    if method==\"stitch\":\n        #deletes nan data points\n      ts=ts[~np.isnan(ts)]\n    elif method==\"zero fill\":\n        #replaces nan data points with 0\n      ts[np.isnan(ts)]=0\n    elif method==\"interpolate\":\n        #interpolates nan data points (linear by default)\n      ts=np.array(pd.Series(ts).interpolate())\n    \n    #collects info about the number of not nan data points\n    length=len(ts)\n    print(f\"cleaned series length: {length}\")\n    statnotnan.append(length)\n    \n    #sample creation from time series, sliding window with calculated step\n    n_samples=length//(sample_length-step)\n    \n    #split time series into segments based on the selected length and step\n    count=0\n    for i in range(n_samples):\n      sample=ts[i*step:i*step+sample_length]\n      #only use samples where average power is above the threshold else discard them\n      if np.mean(sample)>=min_watts:\n        data.append(sample)\n        labels.append(label)\n        count+=1\n    \n    #info about retained data\n    statretained.append(count*sample_length)\n    print(f\"finished: {label}, created {count} samples\\n\")\n\n#output collected info (how many data points)\nprint(f\"retained {np.sum(statnotnan)} out of {np.sum(stattotal)} data points\")\nprint(f\"retained {np.sum(statretained)} data points after sample creation ({np.sum(statretained)//sample_length} samples)\\n\")\n\n#save data in shape (number of samples, minutes*10) and labels in shape (number of samples)\ndata=np.array(data)\nlabels=np.array(labels)\nnp.save(destinationpath+name+\"_data_\"+str(n_mins)+\".npy\", data, allow_pickle=False)\nnp.save(destinationpath+name+\"_labels_\"+str(n_mins)+\".npy\", labels, allow_pickle=False)\n\n#print execution time\nelapsed_time=process_time()-t\nprint(f\"done in {elapsed_time} seconds\\n\")\n\n\nOSError: No such file as SynD.h5"
  },
  {
    "objectID": "posts/notebook_post/sample_creation_(3).html",
    "href": "posts/notebook_post/sample_creation_(3).html",
    "title": "Quarto Basics",
    "section": "",
    "text": "Code\n#!rm -r /home/jovyan/.local/share/jupyter/kernels/nilmtk\n!pip uninstall -y -q nilmtk nilm_metadata\n!python3 -m pip install pandas numpy networkx scipy tables scikit-learn hmmlearn pyyaml matplotlib xgboost pyts\n# Trick to install NILM regardless of its dependencies\n!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilmtk@master\n!python3 -m pip install --no-deps git+https://github.com/nilmtk/nilm_metadata@master\n\n\nRequirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.19.5)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (2.6.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (1.7.2)\nRequirement already satisfied: tables in /opt/conda/lib/python3.9/site-packages (3.6.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.0.1)\nRequirement already satisfied: hmmlearn in /opt/conda/lib/python3.9/site-packages (0.2.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (6.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.4.3)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.9/site-packages (1.6.2)\nRequirement already satisfied: pyts in /opt/conda/lib/python3.9/site-packages (0.12.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\nRequirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.9/site-packages (from tables) (2.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.0.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (8.4.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: numba>=0.48.0 in /opt/conda/lib/python3.9/site-packages (from pyts) (0.54.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (59.1.1)\nRequirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba>=0.48.0->pyts) (0.37.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nCollecting git+https://github.com/nilmtk/nilmtk@master\n  Cloning https://github.com/nilmtk/nilmtk (to revision master) to /tmp/pip-req-build-n33khpe3\n  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilmtk /tmp/pip-req-build-n33khpe3\n  Resolved https://github.com/nilmtk/nilmtk to commit dde510b7b2299958597a6b3885230844c1b7e9da\n  Preparing metadata (setup.py) ... done\nBuilding wheels for collected packages: nilmtk\n  Building wheel for nilmtk (setup.py) ... done\n  Created wheel for nilmtk: filename=nilmtk-0.4.0.dev1+git.dde510b-py3-none-any.whl size=279071 sha256=563beb09bc9828fc29456f6f913b50165f54a959d586726199abf4165057283d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-sk3qzvei/wheels/05/f2/54/7dc6179b2887926915ea9f94c7d02d7c097f9e22a6fdaad502\nSuccessfully built nilmtk\nInstalling collected packages: nilmtk\nSuccessfully installed nilmtk-0.4.0.dev1+git.dde510b\nCollecting git+https://github.com/nilmtk/nilm_metadata@master\n  Cloning https://github.com/nilmtk/nilm_metadata (to revision master) to /tmp/pip-req-build-r1tg6i8d\n  Running command git clone --filter=blob:none -q https://github.com/nilmtk/nilm_metadata /tmp/pip-req-build-r1tg6i8d\n  Resolved https://github.com/nilmtk/nilm_metadata to commit 7ed4bab9062d04cb35c6b6000b451715dc5ab4af\n  Preparing metadata (setup.py) ... done\nBuilding wheels for collected packages: nilm-metadata\n  Building wheel for nilm-metadata (setup.py) ... done\n  Created wheel for nilm-metadata: filename=nilm_metadata-0.2.5-py3-none-any.whl size=24356 sha256=1caad9d0b49a25c3553b343895e4f987a9d939b950da723a5138cfe57a77bbb4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ra9ynsow/wheels/47/14/89/78d651fffdf1c6ba8d7247addd79b87e5236c914c648d03310\nSuccessfully built nilm-metadata\nInstalling collected packages: nilm-metadata\nSuccessfully installed nilm-metadata-0.2.5\n\n\n\n\nCode\nimport h5py\nimport numpy as np\nimport nilmtk\nimport os\nimport pickle\nimport pandas as pd\n\n\n\n\nCode\n#select initial parameters\n\n#name of nilmtk dataset file\noriginname=\"SynD.h5\"\n\n#path of folder with the dataset\noriginpath=\"\"\n\n#where to output processed data\ndestinationpath=\"\"\n\n#desired sample length in minutes, assumes sample rate of 1/6s\nn_mins=15\n\n#samples are created with a sliding window. this is the step as a proportion of resolution\nstep_ratio=0.5\n\n#how to deal with nan values (delete/replace with 0/lerp)\nmethod=\"zero fill\" #\"stitch\", \"zero fill\" or \"interpolate\"\n\n#removes samples with an average power in watts lower than this\nmin_watts=1\n\n\n\n\nCode\n#for measuring execution time\nfrom time import process_time\nt = process_time()\n\n#step calculation based on resolution and step ratio, this is the \nstep_mins=n_mins*step_ratio\nstep=int(step_mins*10)\n\n#name of input file, will be used to name output files\nname=os.path.splitext(originname)[0]\n\n#load dataset\ndataset=nilmtk.DataSet(originpath+originname)\n\n#iterates through all meters and gets unique devices in the dataset\ndevices=[]\nfor building in dataset.buildings:\n  for meter in dataset.buildings[building].elec.submeters().meters:\n    label=meter.appliances[0].metadata.get(\"type\") #string with name of device for example \"fridge\"\n    devices.append(str(label))\ndevices=np.sort(np.unique(np.array(devices))) #removes duplicates and sorts alphabetically\n\n#dictionary of unique devices in the dataset\ndevicedict={}\nfor i, device in enumerate(devices):\n  devicedict[device]=i\n\n#save dictionary to a pickle file\nwith open(\"\"+name+\"_devicedict.pkl\", \"wb\") as f:\n  pickle.dump(devices, f)\n\n#arrays where processed data will be temporarily stored. \n#data and labels store samples and labels \n#the other three store information about total data points, not nan data points and retained data points after sample creation respectively\ndata=[]\nlabels=[]\nstattotal=[]\nstatnotnan=[]\nstatretained=[]\n\n#60s/sample time in seconds=10, this is the number of data points in a sample\nsample_length=n_mins*10\n\n#iterate through all meters\nfor building in dataset.buildings:\n  for meter in dataset.buildings[building].elec.submeters().meters:\n    label=meter.appliances[0].metadata.get(\"type\")\n    #use electrical power data and store in a pandas dataframe\n    df = next(meter.load(physical_quantity='power'))\n    #resamples to 6s, as thats the most commonly shared sample rate\n    df=df.resample(\"6s\").ffill(limit=10)\n    #gets time series of power values, uses active power if possible, else apparent power\n    try:\n        ts = np.array(df.power.active.values)\n    except:\n        try:\n            ts = np.array(df.power.apparent.values)\n        except:\n            raise ValueError\n\n    #collects info about the length of raw ts      \n    print(f\"starting: {label}\")\n    length=len(ts)\n    print(f\"raw series length: {length}\")\n    stattotal.append(length)\n    \n    #transforms the raw time series based on the selected type\n    if method==\"stitch\":\n        #deletes nan data points\n      ts=ts[~np.isnan(ts)]\n    elif method==\"zero fill\":\n        #replaces nan data points with 0\n      ts[np.isnan(ts)]=0\n    elif method==\"interpolate\":\n        #interpolates nan data points (linear by default)\n      ts=np.array(pd.Series(ts).interpolate())\n    \n    #collects info about the number of not nan data points\n    length=len(ts)\n    print(f\"cleaned series length: {length}\")\n    statnotnan.append(length)\n    \n    #sample creation from time series, sliding window with calculated step\n    n_samples=length//(sample_length-step)\n    \n    #split time series into segments based on the selected length and step\n    count=0\n    for i in range(n_samples):\n      sample=ts[i*step:i*step+sample_length]\n      #only use samples where average power is above the threshold else discard them\n      if np.mean(sample)>=min_watts:\n        data.append(sample)\n        labels.append(label)\n        count+=1\n    \n    #info about retained data\n    statretained.append(count*sample_length)\n    print(f\"finished: {label}, created {count} samples\\n\")\n\n#output collected info (how many data points)\nprint(f\"retained {np.sum(statnotnan)} out of {np.sum(stattotal)} data points\")\nprint(f\"retained {np.sum(statretained)} data points after sample creation ({np.sum(statretained)//sample_length} samples)\\n\")\n\n#save data in shape (number of samples, minutes*10) and labels in shape (number of samples)\ndata=np.array(data)\nlabels=np.array(labels)\nnp.save(destinationpath+name+\"_data_\"+str(n_mins)+\".npy\", data, allow_pickle=False)\nnp.save(destinationpath+name+\"_labels_\"+str(n_mins)+\".npy\", labels, allow_pickle=False)\n\n#print execution time\nelapsed_time=process_time()-t\nprint(f\"done in {elapsed_time} seconds\\n\")\n\n\nOSError: No such file as SynD.h5"
  }
]